{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import os\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "import rasterio as rio\n",
    "# import regionmask\n",
    "from fiona.crs import from_epsg \n",
    "from shapely.geometry import Point, Polygon\n",
    "import h5py as h5\n",
    "from glob import glob\n",
    "import json\n",
    "import dask as da\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from rasterio.warp import reproject, Resampling\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_extent_from_neon_h5(fi, nid='CPER'):\n",
    "    \n",
    "    ds = h5.File(fi, 'r')\n",
    "    map_info = str(ds['CPER']['Reflectance']['Metadata']['Coordinate_System']['Map_Info'][()])\n",
    "    epsg = int(ds['CPER']['Reflectance']['Metadata']['Coordinate_System']['EPSG Code'][()])\n",
    "    data_shape = ds['CPER']['Reflectance']['Reflectance_Data'].shape\n",
    "    \n",
    "    # produce the affine transform components\n",
    "    parts = [p.strip() for p in map_info.split(',')]\n",
    "    aff = [float(p) for p in parts[1:7]]\n",
    "    \n",
    "    px, py, ul_x, ul_y = aff[:4]\n",
    "    py = -py\n",
    "    \n",
    "    num_rows, num_cols, num_bands = data_shape\n",
    "    \n",
    "    # produce the points for the extent polygon\n",
    "    ul = Point(ul_x, ul_y)\n",
    "    ur = Point((ul_x +  num_cols*px), ul_y)\n",
    "    ll = Point(ul_x, (ul_y + num_rows*py))\n",
    "    lr = Point((ul_x + num_cols*px), (ul_y + num_rows*py))\n",
    "\n",
    "    extent_poly = Polygon((ul, ur, lr, ll, ul))\n",
    "    \n",
    "    return extent_poly, epsg\n",
    "\n",
    "# make function for reading h5 tiles\n",
    "def read_h5_file(fi, nid='CPER'):\n",
    "    # Read H5 file\n",
    "    f = h5.File(fi, \"r\")\n",
    "    \n",
    "    # spectral\n",
    "    wavelength = f[nid]['Reflectance']['Metadata']['Spectral_Data']['Wavelength'][:]\n",
    "    fwhm = f[nid]['Reflectance']['Metadata']['Spectral_Data']['FWHM'][:]\n",
    "\n",
    "    # CRS\n",
    "    crs_str = f[nid]['Reflectance']['Metadata']['Coordinate_System']['Coordinate_System_String'][()]\n",
    "    crs_epsg = f[nid]['Reflectance']['Metadata']['Coordinate_System']['EPSG Code'][()]\n",
    "    crs_mapinfo = f[nid]['Reflectance']['Metadata']['Coordinate_System']['Map_Info'][()]\n",
    "    crs_proj4 = f[nid]['Reflectance']['Metadata']['Coordinate_System']['Proj4'][()]\n",
    "\n",
    "    #arr = f[nid]['Radiance']['Radiance_Data'][:]\n",
    "    arr = da.array.from_array(f[nid]['Reflectance']['Reflectance_Data'], chunks=(256,256,256))\n",
    "    arr /= float(f[nid]['Reflectance']['Reflectance_Data'].attrs['Scale_Factor'])\n",
    "    \n",
    "    mapinfo_list = [a.strip() for a in str(crs_mapinfo).split(',')]\n",
    "    mapinfo = [float(a) for a in mapinfo_list[1:7]]\n",
    "    mapinfo\n",
    "    pix_size = mapinfo[0]\n",
    "    x = np.arange(mapinfo[2], mapinfo[2] + pix_size*arr.shape[1], pix_size)\n",
    "    y = np.arange(mapinfo[3], mapinfo[3] - pix_size* arr.shape[0], -pix_size)\n",
    "\n",
    "    xr_cube = xr.DataArray(arr, {'y': y, 'x': x, 'bands': wavelength}, dims=['y', 'x', 'bands'])\n",
    "    xr_cube_ma = xr_cube.where(xr_cube != -9999)\n",
    "    \n",
    "    # add in CRS assignemnt!!!!!!!!!!!!\n",
    "    xr_cube_ma = xr_cube_ma.rio.write_crs(int(crs_epsg))\n",
    "    \n",
    "    return xr_cube_ma\n",
    "\n",
    "def resample_h5_spectral(neon_file, weights_file):\n",
    "    \n",
    "    nis_ds = read_h5_file(neon_file)\n",
    "    \n",
    "    \n",
    "    with open(weights_file, 'r') as fb:\n",
    "        weights = json.load(fb)\n",
    "    \n",
    "    sample_bands = []\n",
    "    for k in weights.keys():\n",
    "        b_weights, b_ids = weights[k]\n",
    "        sample_band = (nis_ds.isel(bands=b_ids)*np.array(b_weights)).sum(axis=-1)/ np.array(b_weights).sum()\n",
    "        sample_bands.append(sample_band)\n",
    "            \n",
    "    \n",
    "    sat_ds = xr.concat(sample_bands, dim=list(weights.keys())).rename({'concat_dim':'sat_band'}) # 'sat_band' will be new at dim=0\n",
    "    \n",
    "    return sat_ds\n",
    "\n",
    "def check_valid_pixel_overlap(neon_file, geometry, weights_file):\n",
    "    \n",
    "    nis_ds = resample_h5_spectral(neon_file, weights_file)\n",
    "    #print(nis_ds.spatial_ref)\n",
    "    \n",
    "    try:\n",
    "        sample_clip = nis_ds.rio.clip([geometry])\n",
    "        sample_im_clip = sample_clip.sel(sat_band='L8_Coastal')\n",
    "        \n",
    "        # count pixels vs total\n",
    "        total_pixels = sample_im_clip.size\n",
    "        gt0 = (sample_im_clip > 0.0).sum()\n",
    "        valid_frac = gt0.values/total_pixels\n",
    "        \n",
    "        print(f'valid fraction: {valid_frac}')\n",
    "        if valid_frac > 0.99:\n",
    "            return valid_frac\n",
    "        else:\n",
    "            print('valid pixels are not above 99% of AOI, returning False')\n",
    "            return valid_frac\n",
    "    except Exception as e:\n",
    "        \n",
    "        print(e)\n",
    "        print('not in bounds...')\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-7e6aa40a5862>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpolys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mgen_extent_from_neon_h5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mh5_files\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdesc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mh5_files\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mepsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_extent_from_neon_h5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh5_files\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mfl_gdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGeoDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'geometry'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpolys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'filename'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mdesc\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfrom_epsg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#geodataframe for file extents\n",
    "h5_files = glob('../NEON_spectrometer-orthorectified-surface-directional-reflectance---flightline/*.h5')\n",
    "polys = [gen_extent_from_neon_h5(fi)[0] for fi in h5_files]\n",
    "desc = [os.path.basename(fi).split('.')[0] for fi in h5_files]\n",
    "epsg = gen_extent_from_neon_h5(h5_files[0])[1]\n",
    "\n",
    "fl_gdf = gpd.GeoDataFrame({'geometry': polys, 'filename':desc}, crs=from_epsg(epsg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load AOIS\n",
    "aois = './aois/cper_aois.shp'\n",
    "aoi_gdf = gpd.read_file(aois) # replace with shapefile or other\n",
    "aoi_gdf['area_aoi'] = [g.area for g in aoi_gdf.geometry] # column for area\n",
    "aoi_gdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the areas of overlap of AOI geometries within each flightline\n",
    "aoi_overlap = gpd.overlay(fl_gdf, aoi_gdf, how='intersection')\n",
    "aoi_overlap['area_ovr'] = aoi_overlap.geometry.area\n",
    "\n",
    "# only save the ones that have full overlap\n",
    "aoi_overlap = aoi_overlap.loc[aoi_overlap.area_ovr == aoi_overlap.area_aoi]\n",
    "# aoi_overlap.area_ovr == aoi_overlap.area_aoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find the overlapping flightline with each ao\n",
    "\n",
    "overlap_series = []\n",
    "for geom, desc in zip(aoi_gdf.geometry, aoi_gdf.desc):\n",
    "    \n",
    "    print(desc)\n",
    "    #nfi = os.path.join('../NEON_spectrometer-orthorectified-surface-directional-reflectance---flightline', row[1]['filename'] + '.h5')\n",
    "    overlaps = []\n",
    "    for nfi in h5_files:\n",
    "        \n",
    "        vfac = check_valid_pixel_overlap(nfi, geom, l8_weights_file)\n",
    "        overlaps.append(vfac)\n",
    "        \n",
    "    overlap_series.append(overlaps)\n",
    "\n",
    "    \n",
    "# aoi_fl_df = gpd.GeoDataFrame(series, crs=from_epsg(epsg))\n",
    "# aoi_fl_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ov_thresh = 0.99\n",
    "\n",
    "overlap_arr = np.array(overlap_series)\n",
    "overlap_arr.max(axis=1)\n",
    "list(zip(np.where(overlap_arr > ov_thresh)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(overlap_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = np.where(overlap_arr > ov_thresh)\n",
    "for i in range(rows.shape[0]):\n",
    "    print(overlap_arr[rows[i], cols[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "construct filename and geometry index pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do this smartly\n",
    "ov_idx = np.where(overlap_arr > ov_thresh)\n",
    "_test = []\n",
    "_temp_row, _temp_row_idx = [], []\n",
    "for ix, a in enumerate(ov_idx[0]):\n",
    "    if a in _temp_row:\n",
    "        continue\n",
    "    _temp_row.append(a)\n",
    "    _temp_row_idx.append(ix)\n",
    "    \n",
    "for i,ix in enumerate(_temp_row_idx):\n",
    "    _test.append((_temp_row[i], ov_idx[1][ix]))\n",
    "\n",
    "# assign filename smartly\n",
    "aoi_gdf['filename'] = None\n",
    "for geomidx, fileidx in _test:\n",
    "    aoi_gdf.at[geomidx,'filename'] = h5_files[fileidx]\n",
    "    \n",
    "       \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try the resample_match technique for landsat\n",
    "landsat_file = '../OutputsL7/LS7_20200912_lat40lon10589_r32p34_msk_vmsk_mclds_topshad_rad_srefdem_stdsref.tif'\n",
    "landsat_ds = rxr.open_rasterio(landsat_file)\n",
    "l7_weights_file = './NSS-Satellite-Imagery-with-NEON-AOP-Data/spectral_response/NIS_weights_L7.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loop over the geometries and do the groupby method to produce STD and MEAN per satellite pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists to store results\n",
    "res_L7_means, res_S2_means, res_L7_stds, res_S2_stds =  [],[],[],[]\n",
    "L7_arrs, S2_arrs = [],[]\n",
    "\n",
    "# open the satellite image files\n",
    "landsat_ds = rxr.open_rasterio(landsat_file)\n",
    "s2_ds = rxr.open_rasterio(s2)\n",
    "for desc, geom, fi in aoi_gdf.dropna()[['desc', 'geometry', 'filename']].values:\n",
    "    \n",
    "    print(desc)\n",
    "    \n",
    "    # spectral resample to each satellite\n",
    "    neon_ds_L7 = resample_h5_spectral(fi, l7_weights_file)\n",
    "    neon_ds_S2 = resample_h5_spectral(fi, s2_weights_file)\n",
    "    \n",
    "    # clip to current AOI\n",
    "    neon_ds_L7 = neon_ds_L7.rio.clip([geom], all_touched=True, from_disk=True)\n",
    "    neon_ds_S2 = neon_ds_S2.rio.clip([geom], all_touched=True, from_disk=True)\n",
    "    \n",
    "    # clip landsat and sentinel datasets, add to list\n",
    "    L7_arrs.append(landsat_ds.rio.clip([geom], all_touched=True, from_disk=True))\n",
    "    S2_arrs.append(s2_ds.rio.clip([geom], all_touched=True, from_disk=True))\n",
    "    \n",
    "    # group by for mean\n",
    "    target_res = 30\n",
    "    reduced_L7_mean = (\n",
    "        neon_ds_L7\n",
    "        .groupby(((neon_ds_L7.x//target_res) + 0.5) * target_res)\n",
    "        .mean(dim='x')\n",
    "        .groupby(((neon_ds_L7.y//target_res) + 0.5) * target_res)\n",
    "        .mean(dim='y'))\n",
    "\n",
    "    target_res = 10\n",
    "    reduced_S2_mean = (\n",
    "        neon_ds_S2\n",
    "        .groupby(((neon_ds_S2.x//target_res) + 0.5) * target_res)\n",
    "        .mean(dim='x')\n",
    "        .groupby(((neon_ds_S2.y//target_res) + 0.5) * target_res)\n",
    "        .mean(dim='y'))\n",
    "    \n",
    "    # group by for STD\n",
    "    target_res = 30\n",
    "    reduced_L7_std = (\n",
    "        neon_ds_L7\n",
    "        .groupby(((neon_ds_L7.x//target_res) + 0.5) * target_res)\n",
    "        .std(dim='x')\n",
    "        .groupby(((neon_ds_L7.y//target_res) + 0.5) * target_res)\n",
    "        .std(dim='y'))\n",
    "\n",
    "    target_res = 10\n",
    "    reduced_S2_std = (\n",
    "        neon_ds_S2\n",
    "        .groupby(((neon_ds_S2.x//target_res) + 0.5) * target_res)\n",
    "        .std(dim='x')\n",
    "        .groupby(((neon_ds_S2.y//target_res) + 0.5) * target_res)\n",
    "        .std(dim='y'))\n",
    "    \n",
    "    # append to lists\n",
    "    res_L7_means.append(reduced_L7_mean)\n",
    "    res_S2_means.append(reduced_S2_mean)\n",
    "    res_L7_stds.append(reduced_L7_std)\n",
    "    res_S2_stds.append(reduced_S2_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot Landsat 7 ndvi for AOIs\n",
    "for desc, neon_L7, og_L7 in zip(aoi_gdf.dropna().desc.values, res_L7_means, L7_arrs):\n",
    "    \n",
    "    print(desc)\n",
    "    # NEON NDVI\n",
    "    neon_num = neon_L7.sel(sat_band='L7_NIR') - neon_L7.sel(sat_band='L7_Red')\n",
    "    neon_den = neon_L7.sel(sat_band='L7_NIR') + neon_L7.sel(sat_band='L7_Red')\n",
    "    neon_ndvi = neon_num / neon_den\n",
    "    \n",
    "    # Satellite NDVI\n",
    "    sat_num = og_L7.sel(band=4) - og_L7.sel(band=3)\n",
    "    sat_den = og_L7.sel(band=4) + og_L7.sel(band=3)\n",
    "    sat_ndvi = (sat_num.astype('float')/10000) / (sat_den.astype('float')/10000)\n",
    "    \n",
    "    ## check shapes. if less than 2x2, fuhgeddaboutit\n",
    "    neon_vals = np.flipud(neon_ndvi.values)\n",
    "    sat_vals = sat_ndvi.values\n",
    "    \n",
    "    # hard threshold bad values\n",
    "    neon_vals[neon_vals>1] = 1\n",
    "    neon_vals[neon_vals<-1] = 1\n",
    "    \n",
    "    neon_shape = neon_vals.shape\n",
    "    sat_shape = sat_vals.shape\n",
    "    \n",
    "    if 1 in np.array([neon_shape] + [sat_shape]):\n",
    "        print('array is too small for anything, continuing...')\n",
    "        continue\n",
    "    \n",
    "    # slice if necessary\n",
    "    if neon_shape[0] < sat_shape[0]:\n",
    "        sat_vals = sat_vals[:neon_shape[0],:]\n",
    "            \n",
    "    if neon_shape[1] < sat_shape[1]:\n",
    "        sat_vals = sat_vals[:, :neon_shape[1]]\n",
    "        \n",
    "    if neon_shape[0] > sat_shape[0]:\n",
    "        neon_vals = neon_vals[:sat_shape[0],:]\n",
    "            \n",
    "    if neon_shape[1] > sat_shape[1]:\n",
    "        neon_vals = neon_vals[:, :sat_shape[1]]\n",
    "    \n",
    "    # get the correlation coefficient\n",
    "    corr = np.ma.corrcoef(np.ma.masked_invalid(neon_vals.flatten()), np.ma.masked_invalid(sat_vals.flatten()))[0,1]\n",
    "    \n",
    "    # plot the NDVI\n",
    "    fig, ax = plt.subplots(2,2, figsize=(15,15))\n",
    "    fig.subplots_adjust(left=0.02, bottom=0.06, right=0.95, top=0.94, wspace=0.05)\n",
    "    \n",
    "    im = ax[0,0].imshow(neon_vals)\n",
    "    fig.colorbar(im, ax=ax[0,0])\n",
    "    ax[0,0].set_title('NEON resampled')\n",
    "    \n",
    "    im = ax[0,1].imshow(sat_vals)\n",
    "    fig.colorbar(im, ax=ax[0,1])\n",
    "    ax[0,1].set_title('Landsat 7')\n",
    "    \n",
    "    im = ax[1,0].imshow(sat_vals - neon_vals)\n",
    "    fig.colorbar(im, ax=ax[1,0])\n",
    "    ax[1,0].set_title('Landsat 7 and NEON differenced')\n",
    "    \n",
    "    \n",
    "    ax[1,1].scatter(sat_vals.flatten(), neon_vals.flatten(), alpha=0.4, color='r')\n",
    "    ax[1,1].set_xlabel('Landsat 7 values')\n",
    "    ax[1,1].set_ylabel('NEON resampled values')\n",
    "    ax[1,1].set_title(f'correlation {corr}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (x-python)",
   "language": "python",
   "name": "x-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
